{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rand 2011 Bayesian Analysis\n",
    "\n",
    "This notebook outlines how to begin the duplication the analysis of the Rand et al. 2011 study **\"Dynamic social networks promote cooperation in experiments with humans\"** [Link to Paper](http://humannaturelab.net/wp-content/uploads/2014/10/126-Dynamic-Social-Networks-Promote-Cooperation-in-Experiments-with-Humans.pdf \"Full PDF\")\n",
    "\n",
    "This notebook focuses on using a Bayesian approach.  Just one example is shown.  Refer to the other Cooperation Analysis notebook for the remaining regression formulas to do full replication\n",
    "\n",
    "* [Spreadsheet](https://github.com/Bedrock-py/opal-dataloader-ingest-spreadsheet)\n",
    "* [Stan_GLM](https://github.com/Bedrock-py/opal-analytics-stan)\n",
    "* [select-from-dataframe](https://github.com/Bedrock-py/opal-analytics-select-from-dataframe)\n",
    "* [summarize](https://github.com/Bedrock-py/opal-analytics-summarize)\n",
    "\n",
    "This notebook also requires that bedrock-core be installed locally into the python kernel running this notebook.  This can be installed via command line using:\n",
    "\n",
    "`pip install git+https://github.com/Bedrock-py/bedrock-core.git`\n",
    "\n",
    "The other requirements to run this notebook are:\n",
    "\n",
    "* [`pandas`]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that Bedrock is installed locally.  If the following cell does not run without error, check the install procedure above and try again.  Also, ensure that the kernel selected is the same as the kernel where bedrock-core is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bedrock.client.client import BedrockAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Connection to Bedrock Server\n",
    "\n",
    "This code assumes a local bedrock is hosted at localhost on port 81.  Change the `SERVER` variable to match your server's URL and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "import pprint\n",
    "SERVER = \"http://localhost:81/\"\n",
    "api = BedrockAPI(SERVER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Spreadsheet Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the Spreadsheet Opal.  This Opal is used to load .csv, .xls, and other such files into a Bedrock matrix format.  The code below calls the Bedrock `/dataloaders/ingest` endpoint to check if the `opals.spreadsheet.Spreadsheet.Spreadsheet` opal is installed.\n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the Spreadsheet Opal with pip on the server [Spreadsheet](https://github.com/Bedrock-py/opal-dataloader-ingest-spreadsheet)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.ingest(\"opals.spreadsheet.Spreadsheet.Spreadsheet\")\n",
    "if resp.json():\n",
    "    print(\"Spreadsheet Opal Installed!\")\n",
    "else:\n",
    "    print(\"Spreadsheet Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for STAN GLM Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the STAN GLM Opal. \n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the Stan GLM Opal with pip on the server [Stan GLM](https://github.com/Bedrock-py/opal-analytics-stan)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.stan.Stan.Stan_GLM')\n",
    "if resp.json():\n",
    "    print(\"Stan_GLM Opal Installed!\")\n",
    "else:\n",
    "    print(\"Stan_GLM Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for select-from-dataframe Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the select-from-dataframe Opal. This allows you to filter by row and reduce the columns in a dataframe loaded by the server. \n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the select-from-datafram Opal with pip on the server [select-from-dataframe](https://github.com/Bedrock-py/opal-analytics-select-from-dataframe)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.select-from-dataframe.SelectByCondition.SelectByCondition')\n",
    "if resp.json():\n",
    "    print(\"Select-from-dataframe Opal Installed!\")\n",
    "else:\n",
    "    print(\"Select-from-dataframe Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for summarize Opal\n",
    "\n",
    "The following code block checks the Bedrock server for the summarize Opal. This allows you to summarize a matrix with an optional groupby clause.\n",
    "\n",
    "If the code below shows the Opal is not installed, there are two options:\n",
    "1. If you are running a local Bedrock or are the administrator of the Bedrock server, install the summarize with pip on the server [summarize](https://github.com/Bedrock-py/opal-analytics-summarize)\n",
    "2. If you are not administrator of the Bedrock server, e-mail the Bedrock administrator requesting the Opal be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = api.analytic('opals.summarize.Summarize.Summarize')\n",
    "if resp.json():\n",
    "    print(\"Summarize Opal Installed!\")\n",
    "else:\n",
    "    print(\"Summarize Opal Not Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Data to Bedrock and Create Matrix\n",
    "\n",
    "Now that everything is installed, begin the workflow by uploading the csv data and creating a matrix.  To understand this fully, it is useful to understand how a data loading workflow occurs in Bedrock.\n",
    "\n",
    "1. Create a datasource that points to the original source file\n",
    "2. Generate a matrix from the data source (filters can be applied during this step to pre-filter the data source on load\n",
    "3. Analytics work on the generated matrix\n",
    "\n",
    "** Note: Each time a matrix is generated from a data source it will create a new copy with a new UUID to represent that matrix **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for csv file locally\n",
    "\n",
    "The following code opens the file and prints out the first part.  The file must be a csv file with a header that has labels for each column.  The file is comma delimited csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = 'Rand2011PNAS_cooperation_data.csv'\n",
    "datafile = pandas.read_csv('Rand2011PNAS_cooperation_data.csv')\n",
    "datafile.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Upload the source file to the Bedrock Server\n",
    "\n",
    "This code block uses the Spreadsheet ingest module to upload the source file to Bedrock.  ** Note: This simply copies the file to the server, but does not create a Bedrock Matrix format **\n",
    "\n",
    "If the following fails to upload. Check that the csv file is in the correct comma delimited format with headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ingest_id = 'opals.spreadsheet.Spreadsheet.Spreadsheet'\n",
    "resp = api.put_source('Rand2011', ingest_id, 'default', {'file': open(filepath, \"rb\")})\n",
    "\n",
    "if resp.status_code == 201:\n",
    "    source_id = resp.json()['src_id']\n",
    "    print('Source {0} successfully uploaded'.format(filepath))\n",
    "else:\n",
    "    try:\n",
    "        print(\"Error in Upload: {}\".format(resp.json()['msg']))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        source_id = resp.json()['src_id']\n",
    "        print(\"Using existing source.  If this is not the desired behavior, upload with a different name.\")\n",
    "    except Exception:\n",
    "        print(\"No existing source id provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available data sources for the CSV file\n",
    "\n",
    "Call the Bedrock sources list to see available data sources.  Note, that the `Rand2011` data source should now be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "available_sources = api.list(\"dataloader\", \"sources\").json()\n",
    "s = next(filter(lambda source: source['src_id'] == source_id, available_sources),'None')\n",
    "if s != 'None':\n",
    "    pp = pprint.PrettyPrinter()\n",
    "    pp.pprint(s)\n",
    "else:\n",
    "    print(\"Could not find source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Bedrock Matrix from the CSV Source\n",
    "\n",
    "In order to use the data, the data source must be converted to a Bedrock matrix.  The following code steps through that process.  Here we are doing a simple transform of csv to matrix.  There are options to apply filters (like renaming columns, excluding colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resp = api.create_matrix(source_id, 'rand_mtx')\n",
    "mtx = resp[0]\n",
    "matrix_id = mtx['id']\n",
    "print(mtx)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at basic statistics on the source data\n",
    "\n",
    "Here we can see that Bedrock has computed some basic statistics on the source data.\n",
    "\n",
    "#### For numeric data\n",
    "\n",
    "The quartiles, max, mean, min, and standard deviation are provided\n",
    "\n",
    "#### For non-numeric data\n",
    "\n",
    "The label values and counts for each label are provided.\n",
    "\n",
    "#### For both types\n",
    "\n",
    "The proposed tags and data type that Bedrock is suggesting are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.summarize.Summarize.Summarize\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = []\n",
    "\n",
    "summary_mtx = api.run_analytic(analytic_id, mtx, 'rand_mtx_summary', input_data=inputData, parameter_data=paramsData)\n",
    "output = api.download_results_matrix(matrix_id, summary_mtx['id'], 'matrix.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Filter the data based on a condition\n",
    "\n",
    "Filter the data to only the Static Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.select-from-dataframe.SelectByCondition.SelectByCondition\"\n",
    "inputData = {\n",
    "    'matrix.csv': mtx,\n",
    "    'features.txt': mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"colname\",\"value\":\"condition\"},\n",
    "    {\"attrname\":\"comparator\",\"value\":\"==\"},\n",
    "    {\"attrname\":\"value\",\"value\":\"Static\"}\n",
    "]\n",
    "\n",
    "filtered_mtx = api.run_analytic(analytic_id, mtx, 'rand_static_only', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "filtered_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that Matrix is filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = api.download_results_matrix('rand_mtx', 'rand_static_only', 'matrix.csv', remote_header_file='features.txt')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Bayesian Logistic Regression\n",
    "\n",
    "This uses Stan to perform Bayesian logistic regression comparing the effect of the round on the decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "analytic_id = \"opals.stan.Stan.Stan_GLM\"\n",
    "inputData = {\n",
    "    'matrix.csv': filtered_mtx,\n",
    "    'features.txt': filtered_mtx\n",
    "}\n",
    "\n",
    "paramsData = [\n",
    "    {\"attrname\":\"formula\",\"value\":\"decision0d1c ~ round_num\"},\n",
    "    {\"attrname\":\"family\",\"value\":'logit'},\n",
    "    {\"attrname\":\"chains\",\"value\":\"3\"},\n",
    "    {\"attrname\":\"iter\",\"value\":\"3000\"}\n",
    "]\n",
    "\n",
    "result_mtx = api.run_analytic(analytic_id, mtx, 'rand_bayesian1', input_data=inputData, parameter_data=paramsData)\n",
    "\n",
    "result_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the output of the analysis\n",
    "\n",
    "Here the output of the analysis is downloaded and from here can be visualized and exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_table = api.download_results_matrix('rand_mtx', 'rand_bayesian1', 'matrix.csv')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prior_summary = api.download_results_matrix('rand_mtx', 'rand_bayesian1', 'prior_summary.txt')\n",
    "print(prior_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
